{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Final Model\n",
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import StackingRegressor, RandomForestRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen1_train = pd.read_csv(\"gen1_train_comp_final.csv\")\n",
    "gen2_train = pd.read_csv(\"gen2_train_comp_final.csv\")\n",
    "gen1_test = pd.read_csv(\"gen1_test_comp_final.csv\")\n",
    "gen2_test = pd.read_csv(\"gen2_test_upto9_comp_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, is_gen1=True):\n",
    "    age_col = 'age' if is_gen1 else 'AgeGr'\n",
    "    df[age_col] = df[age_col].round().astype(int)\n",
    "    \n",
    "    group_cols = ['gen1_id', 'sex_assigned_at_birth', 'age'] if is_gen1 else \\\n",
    "                ['gen2_id', 'sex_assigned_at_birth', 'study_parent_sex', 'study_parent_id_new', 'AgeGr']\n",
    "    df = df.groupby(group_cols, as_index=False).mean()\n",
    "    \n",
    "    sort_cols = ['gen1_id', 'age'] if is_gen1 else ['gen2_id', 'AgeGr']\n",
    "    id_col = 'gen1_id' if is_gen1 else 'gen2_id'\n",
    "    \n",
    "    df = df.sort_values(by=sort_cols)\n",
    "    df_grouped = df.groupby(id_col)\n",
    "    \n",
    "    df[\"SHgt_cm_CLEANED\"] = df_grouped[\"SHgt_cm\"].apply(\n",
    "        lambda x: x.interpolate(method=\"linear\").fillna(method='ffill').fillna(method='bfill')).values\n",
    "    \n",
    "    if not is_gen1:\n",
    "        if 'Wgt_kg' in df.columns:\n",
    "            df[\"Wgt_kg_CLEANED\"] = df_grouped[\"Wgt_kg\"].apply(\n",
    "                lambda x: x.interpolate(method=\"linear\").fillna(method='ffill').fillna(method='bfill')).values\n",
    "    \n",
    "    df['sex_assigned_at_birth'] = df['sex_assigned_at_birth'].map({'F': 0, 'M': 1})\n",
    "    if not is_gen1:\n",
    "        df['study_parent_sex'] = df['study_parent_sex'].map({'father': 0, 'mother': 1})\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen1_train = preprocess_data(gen1_train, is_gen1=True)\n",
    "gen2_train = preprocess_data(gen2_train, is_gen1=False)\n",
    "gen1_test = preprocess_data(gen1_test, is_gen1=True)\n",
    "gen2_test = preprocess_data(gen2_test, is_gen1=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df, is_test=False, is_gen1=False):\n",
    "    features_df = df.copy()\n",
    "    id_col = 'gen1_id' if is_gen1 else 'gen2_id'\n",
    "    \n",
    "    # For gen2 data, calculate derived features\n",
    "    if not is_gen1:\n",
    "        grouped = features_df.groupby(id_col)\n",
    "        \n",
    "        # Calculate height velocity (growth rate)\n",
    "        features_df['height_velocity'] = grouped['SHgt_cm_CLEANED'].diff().fillna(0)\n",
    "        \n",
    "        # Calculate BMI\n",
    "        if 'Wgt_kg_CLEANED' in features_df.columns:\n",
    "            features_df['bmi'] = features_df['Wgt_kg_CLEANED'] / ((features_df['SHgt_cm_CLEANED']/100)**2)\n",
    "        else:\n",
    "            features_df['bmi'] = np.nan\n",
    "        \n",
    "        # Calculate height percentile within age group\n",
    "        features_df['height_percentile'] = features_df.groupby('AgeGr')['SHgt_cm_CLEANED'].rank(pct=True)\n",
    "        \n",
    "        # Parent relative height feature\n",
    "        if 'gen1_id' in features_df.columns and 'study_parent_sex' in features_df.columns:\n",
    "            # Encode father vs mother\n",
    "            features_df['is_father'] = (features_df['study_parent_sex'] == 0).astype(int)\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen1_train = create_features(gen1_train, is_gen1=True)\n",
    "gen2_train = create_features(gen2_train, is_gen1=False)\n",
    "gen1_test = create_features(gen1_test, is_test=True, is_gen1=True)\n",
    "gen2_test = create_features(gen2_test, is_test=True, is_gen1=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and target variables\n",
    "target_ages = [10, 11, 12, 13, 14, 15, 16, 18]\n",
    "\n",
    "# Filter train data to include only ages 0-9 (for predicting ages 10-18)\n",
    "gen2_train_features = gen2_train[~gen2_train[\"AgeGr\"].isin(target_ages)]\n",
    "gen2_train_targets = gen2_train[gen2_train[\"AgeGr\"].isin(target_ages)]\n",
    "\n",
    "# Get unique gen2_ids that have both feature data (ages 0-9) and target data (ages 10-18)\n",
    "valid_gen2_ids = list(set(gen2_train_features['gen2_id']).intersection(\n",
    "    set(gen2_train_targets['gen2_id'].unique())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter data to include only those gen2_ids\n",
    "gen2_train_features = gen2_train_features[gen2_train_features['gen2_id'].isin(valid_gen2_ids)]\n",
    "gen2_train_targets = gen2_train_targets[gen2_train_targets['gen2_id'].isin(valid_gen2_ids)]\n",
    "\n",
    "# Create target DataFrame with proper pivoting\n",
    "target_train = gen2_train_targets.pivot(\n",
    "    index=\"gen2_id\", columns=\"AgeGr\", values=\"SHgt_cm_CLEANED\")\n",
    "\n",
    "# Fill NaN values in target if any\n",
    "target_train = target_train.fillna(method='ffill', axis=1).fillna(method='bfill', axis=1)\n",
    "\n",
    "# Get latest height measurements for each person (age 9)\n",
    "latest_heights = gen2_train_features[gen2_train_features['AgeGr'] == 9].set_index('gen2_id')['SHgt_cm_CLEANED']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now merge with parental data\n",
    "train_data = gen2_train_features.merge(\n",
    "    gen1_train, left_on='study_parent_id_new', right_on='gen1_id', how='left', suffixes=('', '_parent'))\n",
    "test_data = gen2_test.merge(\n",
    "    gen1_test, left_on='study_parent_id_new', right_on='gen1_id', how='left', suffixes=('', '_parent'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create advanced features\n",
    "# Fill NaN values before division to avoid NaN results\n",
    "train_data['SHgt_cm_CLEANED'] = train_data['SHgt_cm_CLEANED'].fillna(train_data['SHgt_cm_CLEANED'].median())\n",
    "train_data['SHgt_cm_CLEANED_parent'] = train_data['SHgt_cm_CLEANED_parent'].fillna(train_data['SHgt_cm_CLEANED_parent'].median())\n",
    "test_data['SHgt_cm_CLEANED'] = test_data['SHgt_cm_CLEANED'].fillna(test_data['SHgt_cm_CLEANED'].median())\n",
    "test_data['SHgt_cm_CLEANED_parent'] = test_data['SHgt_cm_CLEANED_parent'].fillna(test_data['SHgt_cm_CLEANED_parent'].median())\n",
    "\n",
    "train_data['height_to_parent_ratio'] = train_data['SHgt_cm_CLEANED'] / train_data['SHgt_cm_CLEANED_parent']\n",
    "test_data['height_to_parent_ratio'] = test_data['SHgt_cm_CLEANED'] / test_data['SHgt_cm_CLEANED_parent']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group train_data by gen2_id to ensure one row per person\n",
    "# Get most recent measurements (highest age) for each person\n",
    "train_data_latest = train_data.loc[train_data.groupby('gen2_id')['AgeGr'].idxmax()]\n",
    "\n",
    "# Ensure target_train and train_data_latest have the same gen2_ids\n",
    "common_gen2_ids = list(set(train_data_latest['gen2_id']).intersection(set(target_train.index)))\n",
    "\n",
    "train_data_latest = train_data_latest[train_data_latest['gen2_id'].isin(common_gen2_ids)]\n",
    "target_train = target_train.loc[common_gen2_ids]\n",
    "\n",
    "# Make sure gen2_ids are in the same order\n",
    "train_data_latest = train_data_latest.set_index('gen2_id').loc[target_train.index].reset_index()\n",
    "target_array = target_train.reset_index(drop=True).values\n",
    "\n",
    "# For test data, get most recent measurements\n",
    "test_data_latest = test_data.loc[test_data.groupby('gen2_id')['AgeGr'].idxmax()]\n",
    "test_gen2_ids = test_data_latest['gen2_id'].copy()\n",
    "\n",
    "# Identify non-ID feature columns\n",
    "id_cols = ['gen1_id', 'gen2_id', 'study_parent_id_new']\n",
    "feature_cols = [col for col in train_data_latest.columns if col not in id_cols]\n",
    "\n",
    "# Remove columns with too many NAs\n",
    "na_threshold = 0.3\n",
    "na_cols = [col for col in feature_cols if train_data_latest[col].isna().mean() > na_threshold]\n",
    "print(f\"Removing {len(na_cols)} columns with >30% NaN values\")\n",
    "feature_cols = [col for col in feature_cols if col not in na_cols]\n",
    "\n",
    "# Make sure all feature columns exist in both datasets\n",
    "for col in feature_cols:\n",
    "    if col not in test_data_latest.columns:\n",
    "        print(f\"Missing column in test data: {col}\")\n",
    "        test_data_latest[col] = np.nan\n",
    "\n",
    "simple_imputer = SimpleImputer(strategy='median')\n",
    "train_data_latest[feature_cols] = simple_imputer.fit_transform(train_data_latest[feature_cols])\n",
    "test_data_latest[feature_cols] = simple_imputer.transform(test_data_latest[feature_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply KNN imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply KNN imputation for better results\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "train_data_latest[feature_cols] = imputer.fit_transform(train_data_latest[feature_cols])\n",
    "test_data_latest[feature_cols] = imputer.transform(test_data_latest[feature_cols])\n",
    "\n",
    "# Create consistent features for training and testing\n",
    "train_features = train_data_latest.drop(columns=[col for col in id_cols if col in train_data_latest.columns])\n",
    "test_features = test_data_latest.drop(columns=[col for col in id_cols if col in test_data_latest.columns])\n",
    "\n",
    "# Ensure column consistency\n",
    "common_columns = list(set(train_features.columns) & set(test_features.columns))\n",
    "train_features = train_features[common_columns]\n",
    "test_features = test_features[common_columns]\n",
    "\n",
    "# Final check for NaN values - clean up any stragglers\n",
    "for col in train_features.columns:\n",
    "    if train_features[col].isna().any():\n",
    "        median_val = train_features[col].median()\n",
    "        train_features[col] = train_features[col].fillna(median_val)\n",
    "        test_features[col] = test_features[col].fillna(median_val)\n",
    "\n",
    "# Verify no NaN values remain\n",
    "nan_count_train = train_features.isna().sum().sum()\n",
    "nan_count_test = test_features.isna().sum().sum()\n",
    "nan_count_target = np.isnan(target_array).sum()\n",
    "\n",
    "print(f\"NaN values in training features: {nan_count_train}\")\n",
    "print(f\"NaN values in test features: {nan_count_test}\")\n",
    "print(f\"NaN values in targets: {nan_count_target}\")\n",
    "\n",
    "if nan_count_train > 0 or nan_count_target > 0:\n",
    "    for i in range(target_array.shape[1]):\n",
    "        if np.isnan(target_array[:, i]).any():\n",
    "            col_median = np.nanmedian(target_array[:, i])\n",
    "            target_array[:, i] = np.nan_to_num(target_array[:, i], nan=col_median)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Validation Split + Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_features, target_array, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a stacking ensemble for each target column\n",
    "base_models = [\n",
    "    ('lgbm', LGBMRegressor(n_estimators=200, max_depth=10, learning_rate=0.05, subsample=0.8, colsample_bytree=0.8)),\n",
    "    ('rf', RandomForestRegressor(n_estimators=200, max_depth=10, min_samples_split=2))\n",
    "]\n",
    "final_estimator = Ridge()\n",
    "\n",
    "# Define pipelines with scaling\n",
    "pipelines = []\n",
    "for name, model in base_models:\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    pipelines.append((name, pipe))\n",
    "\n",
    "stacking_regressors = []\n",
    "for i in range(target_array.shape[1]):\n",
    "    stacking_model = StackingRegressor(estimators=pipelines, final_estimator=final_estimator)\n",
    "    stacking_regressors.append(stacking_model)\n",
    "\n",
    "for i, model in enumerate(stacking_regressors):\n",
    "    model.fit(X_train, y_train[:, i])\n",
    "    val_pred = model.predict(X_val)\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val[:, i], val_pred))\n",
    "    print(f\"Validation RMSE for age {target_ages[i]}: {val_rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.zeros((len(test_features), len(stacking_regressors)))\n",
    "for i, model in enumerate(stacking_regressors):\n",
    "    y_pred[:, i] = model.predict(test_features)\n",
    "\n",
    "# Format predictions\n",
    "prediction_ages = [10, 11, 12, 13, 14, 15, 16, 18]\n",
    "formatted_rows = []\n",
    "for idx, gen2_id in enumerate(test_gen2_ids):\n",
    "    for col_idx, age in enumerate(prediction_ages):\n",
    "        row_id = f\"{gen2_id}_{age}\"\n",
    "        height = y_pred[idx, col_idx]\n",
    "        formatted_rows.append([row_id, height])\n",
    "\n",
    "formatted_predictions = pd.DataFrame(formatted_rows, columns=['gen2id_age', 'SHgt_cm'])\n",
    "formatted_predictions.to_csv(\"test_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.read_csv(\"test_predictions.csv\")\n",
    "output.head(10)\n",
    "output.shape\n",
    "\n",
    "# Get the distinct values\n",
    "distinct_ids_1 = output['gen2id_age'].drop_duplicates()\n",
    "\n",
    "print(distinct_ids_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_output = pd.read_csv(\"gen2_test_solution_template.csv\")\n",
    "ex_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_ids_2 = ex_output['gen2id_age'].drop_duplicates()\n",
    "\n",
    "difference = distinct_ids_1[~distinct_ids_1.isin(distinct_ids_2)]\n",
    "\n",
    "\n",
    "output.drop(output[output['gen2id_age'].isin(difference)].index, inplace=True)\n",
    "\n",
    "output['gen2id_age'].drop_duplicates()\n",
    "output.to_csv(\"test_predictions_catboost.csv\", index=False)\n",
    "\n",
    "output.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DistributedComputing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
